# ===========================================
# 재난대응 AI 에이전트 환경 설정 (템플릿)
# 이 파일을 .env로 복사하고 값을 채우세요
# ===========================================

# vLLM 서버 설정
VLLM_SERVER_URL=http://localhost:8000/v1
VLLM_API_KEY=EMPTY

# 모델 설정
LLM_MODEL_NAME=LGAI-EXAONE/EXAONE-4.0-32B
MAX_TOKENS=16384

# API Keys (실제 키로 교체하세요)
MISTRAL_API_KEY=your_mistral_api_key_here
KMA_API_KEY=your_kma_api_key_here
SERPAPI_API_KEY=your_serpapi_key_here

# ===========================================
# GPU 할당 전략 (RTX A5000 24GB x4)
# ===========================================
# GPU 0,1,2,3: vLLM (EXAONE-32B FP16, TP=4) - run_vllm.sh에서 설정
# RAG Embedding: CPU 모드
# ===========================================

# RAG/Embedding: CPU 모드 (빈 값 = CPU)
RAG_GPU_DEVICE=

# FAISS 인덱스 모드: "gpu" 또는 "cpu"
# - gpu: 검색 속도 빠름, GPU 메모리 사용
# - cpu: 메모리 효율적, OOM 위험 없음 (권장)
FAISS_MODE=cpu

# Gradio 앱은 GPU 사용 안함 (vLLM이 전부 사용)
CUDA_VISIBLE_DEVICES=

# Gradio 설정
GRADIO_HOST=0.0.0.0
GRADIO_PORT=7865
