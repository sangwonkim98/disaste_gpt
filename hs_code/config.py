"""
Qwen3-32B-AWQ ê¸°ë°˜ êµì§ì› ì—…ë¬´ì§€ì› ì±—ë´‡ ì„¤ì •
vLLM ì„œë²„ + LangChain RAG + Mistral OCR
"""

import os
import glob
import logging
import tempfile
import yaml
from pathlib import Path
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ================================
# ì„¤ì • ë¡œë“œ í•¨ìˆ˜
# ================================
def load_config():
    """
    ì„¤ì • ë¡œë“œ ìš°ì„ ìˆœìœ„:
    1. í™˜ê²½ë³€ìˆ˜ (.env í¬í•¨)
    2. config.yaml
    3. ì½”ë“œ ë‚´ ê¸°ë³¸ê°’
    """
    # 1. .env íŒŒì¼ ë¡œë“œ
    load_dotenv()
    
    # 2. config.yaml íŒŒì¼ ë¡œë“œ
    config_path = Path(__file__).parent / "config.yaml"
    yaml_config = {}
    
    if config_path.exists():
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                yaml_config = yaml.safe_load(f)
            logger.info(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
        except Exception as e:
            logger.error(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {config_path}")

    return yaml_config

# ì„¤ì • ë¡œë“œ ì‹¤í–‰
CONFIG = load_config()

# ================================
# í—¬í¼ í•¨ìˆ˜: ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
# ================================
def get_conf(key_path, default=None, env_key=None):
    """
    YAML ì„¤ì •ê³¼ í™˜ê²½ë³€ìˆ˜ë¥¼ ë™ì‹œì— í™•ì¸í•˜ì—¬ ê°’ì„ ë°˜í™˜
    - key_path: 'llm.parameters.temperature' ì™€ ê°™ì€ ì (.)ìœ¼ë¡œ êµ¬ë¶„ëœ ê²½ë¡œ
    - env_key: 'TEMPERATURE' ì™€ ê°™ì€ í™˜ê²½ë³€ìˆ˜ í‚¤ (ì˜¤ë²„ë¼ì´ë“œìš©)
    """
    # 1. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if env_key and os.getenv(env_key):
        return os.getenv(env_key)
    
    # 2. YAML ì„¤ì • í™•ì¸
    keys = key_path.split('.')
    value = CONFIG
    for k in keys:
        if isinstance(value, dict) and k in value:
            value = value[k]
        else:
            return default
            
    return value

# ================================
# í”„ë¡œì íŠ¸ ì •ë³´
# ================================
PROJECT_NAME = get_conf("project.name", "ì¬ë‚œëŒ€ì‘ AI ì—ì´ì „íŠ¸")
VERSION = get_conf("project.version", "v5.0")
DESCRIPTION = get_conf("project.description", "")

# ================================
# ëª¨ë¸ ì„¤ì •
# ================================
# vLLM ì„œë²„ ì„¤ì •
VLLM_SERVER_URL = os.getenv("VLLM_SERVER_URL", "http://0.0.0.0:8010")
VLLM_API_KEY = os.getenv("VLLM_API_KEY", "EMPTY")

# LLM ì„¤ì •
LLM_MODEL_NAME = get_conf("llm.model_name", "LGAI-EXAONE/EXAONE-4.0-32B")
ENABLE_REASONING = get_conf("llm.enable_reasoning", True)
# [ìµœì í™”] Max Tokensë¥¼ ëª¨ë¸ í•œê³„(4096)ì— ë§ì¶° 2048ë¡œ í•˜í–¥ ì¡°ì •
MAX_TOKENS = int(get_conf("llm.max_tokens", 2048))

# íŒŒë¼ë¯¸í„° (í™˜ê²½ë³€ìˆ˜ë¡œë„ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •)
TEMPERATURE = float(get_conf("llm.parameters.temperature", 0.6, "TEMPERATURE"))
TOP_P = float(get_conf("llm.parameters.top_p", 0.95, "TOP_P"))
TOP_K = int(get_conf("llm.parameters.top_k", 20, "TOP_K"))
MIN_P = float(get_conf("llm.parameters.min_p", 0, "MIN_P"))

# ì„ë² ë”© ëª¨ë¸
EMBEDDING_MODEL = get_conf("embedding.model", "dragonkue/BGE-m3-ko")
# ì„ë² ë”© ë””ë°”ì´ìŠ¤ (GPU 2ë²ˆ ì‚¬ìš© - vLLMì€ GPU 0,1 ì‚¬ìš©)
EMBEDDING_DEVICE = get_conf("embedding.device", "cuda:2", "EMBEDDING_DEVICE")

# ================================
# RAG ì„¤ì •
# ================================
CHUNK_SIZE = int(get_conf("rag.chunk_size", 5000))
CHUNK_OVERLAP = int(get_conf("rag.chunk_overlap", 3000))
TOP_K_RESULTS = int(get_conf("rag.top_k_results", 8))

# ì¬ìˆœìœ„í™”(Reranking) ì„¤ì •
RERANKING_ENABLED = get_conf("rag.reranking.enabled", True)
RERANK_TOP_N = int(get_conf("rag.reranking.top_n", 24))
CROSS_ENCODER_MODEL = get_conf("embedding.cross_encoder_model", "BAAI/bge-reranker-base")
CROSS_ENCODER_TOP_N = int(get_conf("rag.reranking.cross_encoder_top_n", 8))
CROSS_ENCODER_RERANKING_ENABLED = RERANKING_ENABLED # í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€

# ì¿¼ë¦¬ ì¬ì‘ì„± ì„¤ì •
QUERY_REWRITING_ENABLED = get_conf("rag.query_rewriting.enabled", True)
QUERY_REWRITE_NUM = int(get_conf("rag.query_rewriting.num_rewrites", 3))
QUERY_REWRITE_TIMEOUT = int(get_conf("rag.query_rewriting.timeout", 25))
ORIGINAL_QUERY_WEIGHT = float(get_conf("rag.query_rewriting.original_query_weight", 0.6))
REWRITE_QUERIES_WEIGHT = float(get_conf("rag.query_rewriting.rewrite_queries_weight", 0.4))
CANDIDATES_PER_QUERY = 12 # ê¸°ë³¸ê°’ ê³ ì •

# ë‹¤ì–‘ì„± ì„¤ì •
MAX_CHUNKS_PER_DOC = int(get_conf("rag.diversity.max_chunks_per_doc", 3))

# ================================
# API í‚¤ ì„¤ì •
# ================================
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "")
KMA_API_KEY = os.getenv("KMA_API_KEY", "")

# ================================
# ì‹œìŠ¤í…œ ë©”ì‹œì§€
# ================================
SYSTEM_MESSAGE_DEFAULT = """ë‹¹ì‹ ì€ ì¬ë‚œ ëŒ€ì‘ ë° ê¸°ìƒ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì¤‘ìš”: ë„êµ¬ ì‚¬ìš© ê·œì¹™]
1. **ê¸°ìƒì²­(KMA) ë„êµ¬ í˜¸ì¶œ ì‹œ ì ˆëŒ€ ì¢Œí‘œë‚˜ ì‹œê°„ì„ ì§ì ‘ ê³„ì‚°í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
   - `nx`, `ny`, `base_date`, `base_time` íŒŒë¼ë¯¸í„°ëŠ” ì‹œìŠ¤í…œì´ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤.
   - ë‹¹ì‹ ì€ ì˜¤ì§ **`location`** (ì˜ˆ: 'ì„œìš¸', 'ìš©ì¸', 'ë¶€ì‚°') íŒŒë¼ë¯¸í„°ë§Œ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤.

2. **ìƒí™©ë³„ ë„êµ¬ ì„ íƒ ê°€ì´ë“œ:**
   - "ì§€ê¸ˆ ë‚ ì”¨ ì–´ë•Œ?", "í˜„ì¬ ê¸°ì˜¨ì€?" â†’ **`kma_get_ultra_srt_ncst`** (ì´ˆë‹¨ê¸°ì‹¤í™©)
   - "ì˜¤ëŠ˜ ì˜¤í›„ ë‚ ì”¨ëŠ”?", "ë‚´ì¼ ë¹„ ì™€?" â†’ **`kma_get_vilage_fcst`** (ë‹¨ê¸°ì˜ˆë³´)
   - "í–¥í›„ 3ì‹œê°„ ë’¤ ë‚ ì”¨ëŠ”?" â†’ **`kma_get_ultra_srt_fcst`** (ì´ˆë‹¨ê¸°ì˜ˆë³´)
   - "ë‹¤ìŒì£¼ ë‚ ì”¨ëŠ”?", "ì£¼ë§ ë‚ ì”¨ ì–´ë•Œ?" â†’ **`kma_get_mid_land_fcst`** (ì¤‘ê¸°ì˜ˆë³´)
   - "íƒœí’ ì˜¤ê³  ìˆì–´?", "í­ì—¼ ì£¼ì˜ë³´ ìˆì–´?" â†’ **`kma_get_wthr_wrn_msg`** (ê¸°ìƒíŠ¹ë³´)
   - "ë°©ê¸ˆ ì§€ì§„ ë‚¬ì–´?" â†’ **`kma_get_eqk_msg_list`** (ì§€ì§„ì •ë³´)
   - ê·¸ ì™¸ ìµœì‹  ë‰´ìŠ¤ë‚˜ ì¼ë°˜ ì •ë³´ â†’ **`serpapi_web_search`**

3. ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
"""

SYSTEM_MESSAGE = get_conf("system_prompt", SYSTEM_MESSAGE_DEFAULT)

# ================================
# ê²½ë¡œ ì„¤ì •
# ================================
PROJECT_ROOT = Path(__file__).parent
DATA_DIR = PROJECT_ROOT / "data"
CACHE_DIR = PROJECT_ROOT / "cache"

EMBEDDING_CACHE_DIR = CACHE_DIR / "embeddings"
VECTORSTORE_CACHE_DIR = CACHE_DIR / "vectorstore"
OCR_OUTPUT_DIR = CACHE_DIR / "ocr"
TEMP_DIR = PROJECT_ROOT / "temp"
MODEL_CACHE_DIR = str(CACHE_DIR / "models")

PDF_FILES = sorted(glob.glob(str(DATA_DIR / "*.pdf")))

# ================================
# Gradio ì„¤ì •
# ================================
GRADIO_HOST = os.getenv("GRADIO_HOST", "0.0.0.0")
GRADIO_PORT = int(get_conf("gradio.port", 7865, "GRADIO_PORT"))
GRADIO_THEME = get_conf("gradio.theme", "soft")

# ================================
# ê¸°íƒ€ ì„¤ì •
# ================================
CUDA_VISIBLE_DEVICES = os.getenv("CUDA_VISIBLE_DEVICES", "0")
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
LOG_DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# ================================
# í™˜ê²½ ì„¤ì • í•¨ìˆ˜
# ================================
def setup_environment():
    import tempfile
    
    # HuggingFace ìºì‹œ
    os.environ["HF_HOME"] = MODEL_CACHE_DIR
    os.environ["HUGGINGFACE_CACHE"] = MODEL_CACHE_DIR
    os.environ["TRANSFORMERS_CACHE"] = str(Path(MODEL_CACHE_DIR) / "transformers")
    
    # CUDA
    if CUDA_VISIBLE_DEVICES:
        os.environ["CUDA_VISIBLE_DEVICES"] = CUDA_VISIBLE_DEVICES
    
    # SerpAPI (ê¸°ë³¸ê°’ ì²˜ë¦¬)
    if not os.getenv("SERPAPI_API_KEY"):
        os.environ["SERPAPI_API_KEY"] = "c5ea5598e8e0976c998a5f8e5dce4ab6172d59875a1439ec45ae349d099dd26f"
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬
    temp_dir = PROJECT_ROOT.parent / "temp_gradio"
    temp_dir.mkdir(exist_ok=True, mode=0o755)
    temp_dir_str = str(temp_dir)
    
    os.environ['GRADIO_TEMP_DIR'] = temp_dir_str
    os.environ['TMPDIR'] = temp_dir_str
    os.environ['TMP'] = temp_dir_str
    os.environ['TEMP'] = temp_dir_str
    tempfile.tempdir = temp_dir_str
    
    print(f"ğŸ“ ì„ì‹œ ë””ë ‰í† ë¦¬: {temp_dir}")
    print(f"âš™ï¸  ì„¤ì • íŒŒì¼: hs_code/config.yaml")

def ensure_directories():
    directories = [
        DATA_DIR, CACHE_DIR, EMBEDDING_CACHE_DIR, 
        VECTORSTORE_CACHE_DIR, OCR_OUTPUT_DIR, TEMP_DIR, Path(MODEL_CACHE_DIR)
    ]
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)

def validate_config():
    if not VLLM_SERVER_URL:
        return False
    if not PDF_FILES:
        print(f"âŒ PDF íŒŒì¼ì´ {DATA_DIR}ì— ì—†ìŠµë‹ˆë‹¤.")
        return False
    return True

# ì´ˆê¸°í™” ì‹¤í–‰
setup_environment()
ensure_directories()

if __name__ == "__main__":
    print(f"ğŸ”§ {PROJECT_NAME} {VERSION}")
    print(f"ğŸ“ {DESCRIPTION}")
    print(f"ğŸ¤– Model: {LLM_MODEL_NAME} (Temp: {TEMPERATURE})")
    print(f"ğŸ“ Config loaded from yaml")
